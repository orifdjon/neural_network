{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-59cac1726646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import collections\n",
    "import random\n",
    "import math\n",
    "from pylab import *\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "import torch.autograd as autograd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(\"all_set.xlsx\")\n",
    "inputs_indx = [\"frequency\",\"angle_of_attack\", \"chord_lenght\", \"free-streem_velocity\", \"suction_side\"]\n",
    "label_indx = [\"sound_pressure\"]\n",
    "print(len(dataset))\n",
    "dataset.drop_duplicates()\n",
    "print(len(dataset))\n",
    "dataset['frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.hist(dataset[inputs_indx[i]], bins = 15)\n",
    "    plt.title(inputs_indx[i])\n",
    "plt.savefig('hist1.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 7))\n",
    "plt.hist(dataset[label_indx[0]], bins = 15)\n",
    "plt.title(label_indx[0])\n",
    "plt.savefig('hist2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.boxplot(dataset[inputs_indx[i]], vert=False)\n",
    "    plt.title(inputs_indx[i])\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 7))\n",
    "plt.boxplot(dataset[label_indx[0]], vert=False)\n",
    "plt.title(label_indx[0])\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_of_dataset = np.array(dataset.corr())\n",
    "\n",
    "plt.figure(figsize=(18,11)) \n",
    "mask = np.zeros_like(corr_of_dataset) \n",
    "mask[np.triu_indices_from(mask)] = True \n",
    "sns.heatmap(corr_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask) \n",
    "plt.savefig('heat_corr.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_to_scatter = [[inputs_indx[0], inputs_indx[1]], [inputs_indx[0], inputs_indx[2]],\\\n",
    "                  [inputs_indx[0], inputs_indx[3]],[inputs_indx[0], inputs_indx[4]],\\\n",
    "                  [inputs_indx[0], label_indx[0]], [inputs_indx[1], inputs_indx[2]],\\\n",
    "                  [inputs_indx[1], inputs_indx[3]], [inputs_indx[1], inputs_indx[4]], [inputs_indx[1], label_indx[0]],\\\n",
    "                  [inputs_indx[2], inputs_indx[3]], [inputs_indx[2], inputs_indx[4]], [inputs_indx[2], label_indx[0]],\\\n",
    "                  [inputs_indx[3], inputs_indx[4]],[inputs_indx[3], label_indx[0]], [inputs_indx[4], label_indx[0]]] \n",
    "plt.figure(figsize=(23, 15)) \n",
    "for i in range(len(atr_to_scatter)): \n",
    "    plt.subplot(3, 5, i+1) \n",
    "    plt.scatter(dataset[atr_to_scatter[i][0]], dataset[atr_to_scatter[i][1]]) \n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1])) \n",
    "    plt.savefig('scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)\n",
    "pap1=np.percentile(dataset['frequency'], 95)\n",
    "pap2=np.percentile(dataset['frequency'], 5)\n",
    "prh1=np.percentile(dataset['suction_side'], 95)\n",
    "prh2=np.percentile(dataset['suction_side'], 5)\n",
    "length=len(dataset)\n",
    "for i in range(length):\n",
    "    if(dataset['frequency'][i] > pap1 or dataset['frequency'][i] < pap2):\n",
    "        dataset=dataset.drop([i])\n",
    "    else:\n",
    "        if(dataset['suction_side'][i] > prh1 or dataset['suction_side'][i] < prh2):\n",
    "            dataset=dataset.drop([i])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.hist(dataset[inputs_indx[i]], bins = 15)\n",
    "    plt.title(inputs_indx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 7))\n",
    "plt.hist(dataset[label_indx[0]], bins = 15)\n",
    "plt.title(label_indx[0])\n",
    "plt.savefig('hist2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.boxplot(dataset[inputs_indx[i]], vert=False)\n",
    "    plt.title(inputs_indx[i])\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 7))\n",
    "plt.boxplot(dataset[label_indx[0]], vert=False)\n",
    "plt.title(label_indx[0])\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_of_dataset = np.array(dataset.corr())\n",
    "\n",
    "plt.figure(figsize=(18,11)) \n",
    "mask = np.zeros_like(corr_of_dataset) \n",
    "mask[np.triu_indices_from(mask)] = True \n",
    "sns.heatmap(corr_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask) \n",
    "plt.savefig('heat_corr.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_to_scatter = [[inputs_indx[0], inputs_indx[1]], [inputs_indx[0], inputs_indx[2]],\\\n",
    "                  [inputs_indx[0], inputs_indx[3]],[inputs_indx[0], inputs_indx[4]],\\\n",
    "                  [inputs_indx[0], label_indx[0]], [inputs_indx[1], inputs_indx[2]],\\\n",
    "                  [inputs_indx[1], inputs_indx[3]], [inputs_indx[1], inputs_indx[4]], [inputs_indx[1], label_indx[0]],\\\n",
    "                  [inputs_indx[2], inputs_indx[3]], [inputs_indx[2], inputs_indx[4]], [inputs_indx[2], label_indx[0]],\\\n",
    "                  [inputs_indx[3], inputs_indx[4]],[inputs_indx[3], label_indx[0]], [inputs_indx[4], label_indx[0]]] \n",
    "plt.figure(figsize=(23, 15)) \n",
    "for i in range(len(atr_to_scatter)): \n",
    "    plt.subplot(3, 5, i+1) \n",
    "    plt.scatter(dataset[atr_to_scatter[i][0]], dataset[atr_to_scatter[i][1]]) \n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1])) \n",
    "    plt.savefig('scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset1=dataset.drop(columns=['sound_pressure'])\n",
    "pca = PCA(n_components = 5)\n",
    "dataset1 = pca.fit_transform(dataset1)\n",
    "print(len(dataset1))\n",
    "dataset1=dataset1.transpose()\n",
    "dataset_new=dataset.copy()\n",
    "dataset_new[inputs_indx[0]]=dataset1[0]\n",
    "dataset_new[inputs_indx[1]]=dataset1[1]\n",
    "dataset_new[inputs_indx[2]]=dataset1[2]\n",
    "dataset_new[inputs_indx[3]]=dataset1[3]\n",
    "dataset_new[inputs_indx[4]]=dataset1[4]\n",
    "\n",
    "\n",
    "corr_of_dataset = np.array(dataset_new.corr())\n",
    "\n",
    "plt.figure(figsize=(18,11)) \n",
    "mask = np.zeros_like(corr_of_dataset) \n",
    "mask[np.triu_indices_from(mask)] = True \n",
    "sns.heatmap(corr_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask) \n",
    "print(\"__________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_to_scatter = [[inputs_indx[0], inputs_indx[1]], [inputs_indx[0], inputs_indx[2]],\\\n",
    "                  [inputs_indx[0], inputs_indx[3]],[inputs_indx[0], inputs_indx[4]],\\\n",
    "                  [inputs_indx[0], label_indx[0]], [inputs_indx[1], inputs_indx[2]],\\\n",
    "                  [inputs_indx[1], inputs_indx[3]], [inputs_indx[1], inputs_indx[4]], [inputs_indx[1], label_indx[0]],\\\n",
    "                  [inputs_indx[2], inputs_indx[3]], [inputs_indx[2], inputs_indx[4]], [inputs_indx[2], label_indx[0]],\\\n",
    "                  [inputs_indx[3], inputs_indx[4]],[inputs_indx[3], label_indx[0]], [inputs_indx[4], label_indx[0]]] \n",
    "plt.figure(figsize=(23, 15)) \n",
    "for i in range(len(atr_to_scatter)): \n",
    "    plt.subplot(3, 5, i+1) \n",
    "    plt.scatter(dataset_new[atr_to_scatter[i][0]], dataset_new[atr_to_scatter[i][1]]) \n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1])) \n",
    "    plt.savefig('scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset1=dataset.drop(columns=['PE'])\n",
    "#pca = PCA(n_components = 2)\n",
    "#dataset1 = pca.fit_transform(dataset1)\n",
    "#print(len(dataset1))\n",
    "#dataset1=dataset1.transpose()\n",
    "#dataset_new=dataset.drop(columns=['AP', 'RH'])\n",
    "#dataset_new['AT']=dataset1[0]\n",
    "#dataset_new['V']=dataset1[1]\n",
    "#dataset_new=dataset_new.rename(index=str, columns={\"AT\": \"first\", \"V\": \"second\"})\n",
    "#dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler() \n",
    "dataset_new.loc[:, inputs_indx] = scaler.fit_transform(dataset_new.loc[:, inputs_indx]) \n",
    "dataset_new.loc[:, label_indx] = scaler.fit_transform(dataset_new.loc[:, label_indx]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset_new))\n",
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.hist(dataset_new[inputs_indx[i]], bins = 15)\n",
    "    plt.title(inputs_indx[i])\n",
    "plt.savefig('hist1.png', bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 7))\n",
    "plt.hist(dataset_new[label_indx[0]], bins = 15)\n",
    "plt.title(label_indx[0])\n",
    "plt.savefig('hist2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.boxplot(dataset_new[inputs_indx[i]], vert=False)\n",
    "    plt.title(inputs_indx[i])\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 7))\n",
    "plt.boxplot(dataset_new[label_indx[0]], vert=False)\n",
    "plt.title(label_indx[0])\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_to_scatter = [[inputs_indx[0], inputs_indx[1]], [inputs_indx[0], inputs_indx[2]],\\\n",
    "                  [inputs_indx[0], inputs_indx[3]],[inputs_indx[0], inputs_indx[4]],\\\n",
    "                  [inputs_indx[0], label_indx[0]], [inputs_indx[1], inputs_indx[2]],\\\n",
    "                  [inputs_indx[1], inputs_indx[3]], [inputs_indx[1], inputs_indx[4]], [inputs_indx[1], label_indx[0]],\\\n",
    "                  [inputs_indx[2], inputs_indx[3]], [inputs_indx[2], inputs_indx[4]], [inputs_indx[2], label_indx[0]],\\\n",
    "                  [inputs_indx[3], inputs_indx[4]],[inputs_indx[3], label_indx[0]], [inputs_indx[4], label_indx[0]]] \n",
    "plt.figure(figsize=(23, 10)) \n",
    "for i in range(len(atr_to_scatter)): \n",
    "    plt.subplot(3, 5, i+1) \n",
    "    plt.scatter(dataset_new[atr_to_scatter[i][0]], dataset_new[atr_to_scatter[i][1]]) \n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1])) \n",
    "    plt.savefig('scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=dataset_new.values\n",
    "X = array[:,0:5]\n",
    "\n",
    "Y = array[:,5]\n",
    "\n",
    "model = ExtraTreesRegressor()\n",
    "\n",
    "model.fit(X, Y)\n",
    "\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new=dataset_new.drop(columns=['angle_of_attack', 'chord_lenght', 'suction_side'])\n",
    "dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new=pd.DataFrame(np.array(dataset_new))\n",
    "data = np.array(list(zip(dataset_new[0], dataset_new[1], dataset_new[2])))\n",
    "\n",
    "train_border = [0, int(len(data)*0.6)]\n",
    "valid_border = [int(len(data)*0.6), int(len(data)*0.9)]\n",
    "test_border = [int(len(data)*0.9), len(data)]\n",
    "\n",
    "train_data = data[train_border[0]: train_border[1]]\n",
    "valid_data = data[valid_border[0]: valid_border[1]]\n",
    "test_data = data[test_border[0]: test_border[1]]\n",
    "\n",
    "print('\\n', len(train_data), len(valid_data), len(test_data))\n",
    "train_data=pd.DataFrame(np.array(train_data))\n",
    "valid_data=pd.DataFrame(np.array(valid_data))\n",
    "test_data=pd.DataFrame(np.array(test_data))\n",
    "valid_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Поделил данные\n",
    "train_data.to_csv(\"learn_data.csv\")\n",
    "valid_data.to_csv(\"valid_data.csv\")\n",
    "test_data.to_csv(\"test_data.csv\")\n",
    "dataset_new.to_csv(\"all_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
